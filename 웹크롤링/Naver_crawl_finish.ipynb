{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "\n",
    "URL = 'https://comic.naver.com/webtoon/finish'\n",
    "html = requests.get(URL).text # html 문서 전체를 긁어서 출력해줌, .text는 태그 제외하고 text만 출력되게 함\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "num=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = [] ; title_list = [] ; rate_list = []; author_list = [] ; day_list = [] ; genre_list = [] ; story_list = [] ; platform_list = []; age_list=[] ; img_list=[]; web_list = []; comp_list = []; free_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 92.0.4515\n",
      "Get LATEST driver version for 92.0.4515\n",
      "Driver [C:\\Users\\queenSSH\\.wdm\\drivers\\chromedriver\\win32\\92.0.4515.43\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver=webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "driver.implicitly_wait(10)\n",
    "driver.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = driver.find_elements_by_xpath('//a[contains(@onclick,\"lst.title\")]')\n",
    "\n",
    "for i in range(len(page)):\n",
    "    sleep(0.5) # 크롤링 중간 중간 텀을 주어 과부하 생기지 않도록\n",
    "    page = driver.find_elements_by_xpath('//a[contains(@onclick,\"lst.title\")]')\n",
    "\n",
    "    page[i].click()\n",
    "    \n",
    "    sleep(0.5)\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser') # 이동한 페이지 주소 읽고 파싱\n",
    "    \n",
    "    title = soup.find_all('h2') # 두 번째 h2태그에 있음\n",
    "    title = title[1].get_text().split()[0]\n",
    "    \n",
    "    \n",
    "    id_list.append(i) ; num += 1  # id 리스트에 추가\n",
    "    title_list.append(title)  # 제목 리스트에 추가\n",
    "    platform_list.append('네이버 웹툰') # 플랫폼 리스트에 추가\n",
    "\n",
    "    \n",
    "    \n",
    "    author = soup.find_all('h2') # 두 번째 h2태그에 있음\n",
    "    author = author[1].find('span', {'class' : 'wrt_nm'}).text[8:] # 7칸의 공백 후 8번 째부터 작가 이름임\n",
    "    author_list.append(author) # 작가 리스트에 추가    \n",
    "    \n",
    "    genre = soup.find('span', {'class' : 'genre'}).text # 장르 수집\n",
    "    genre_list.append(genre) # 장르 리스트에 추가\n",
    "\n",
    "    story = soup.find_all('p') # 줄거리 수집\n",
    "    story = str(story[3])\n",
    "    story = story.replace('<p>', '').replace('</p>', '').replace('<br/>', '\\n') # <br>을 개행으로 바꾸기\n",
    "    story_list.append(story) # 줄거리 리스트에 추가\n",
    "    \n",
    "    try:\n",
    "        age = soup.find('span',{'class':'age'}).text #age수집\n",
    "        age = age.replace('세 이용가', '')\n",
    "\n",
    "        if age == '전체연령가':\n",
    "            age = 0 \n",
    "            age_list.append(age) #전체 연령가이면 0으로 추가\n",
    "        else:\n",
    "            age = float(age)\n",
    "            age_list.append(age) #age리스트에 추가\n",
    "            \n",
    "    except:\n",
    "        age_list.append(0)\n",
    "    \n",
    "\n",
    "    \n",
    "    #썸네일\n",
    "    thumb = soup.find_all(\"div\", {\"class\" : \"thumb\"})\n",
    "    \n",
    "    for m in thumb :\n",
    "        week_check = m.a.get('href')\n",
    "        week_check = week_check[-3:]\n",
    "        \n",
    "    imgUrl = m.find_all('img')    \n",
    "    img_link = imgUrl[0].get('src')   \n",
    "    img_list.append(img_link)\n",
    "    \n",
    "    #웹주소\n",
    "    web = soup.find_all('head')\n",
    "    web = soup.find('meta',{'property':'og:url'})\n",
    "    web = str(web)\n",
    "    web = web.split('\"')\n",
    "    web_list.append(web[1])\n",
    "    \n",
    "    #유료,무료\n",
    "    \n",
    "    #완결, 미완결\n",
    "    comp_list.append(1)\n",
    "    \n",
    "    driver.back() # 뒤로 가기\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "total_data = pd.DataFrame(columns = cols)\n",
    "total_data['id'] = id_list\n",
    "total_data['title'] = title_list\n",
    "total_data['author'] = author_list\n",
    "total_data['genre'] = genre_list\n",
    "total_data['story'] = story_list\n",
    "total_data['platform'] = platform_list\n",
    "total_data['age'] = age_list\n",
    "total_data['complete'] = comp_list\n",
    "total_data['thumbnail'] = img_list\n",
    "total_data['web'] = web_list\n",
    "total_data.to_csv('네이버_웹툰_완결.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
