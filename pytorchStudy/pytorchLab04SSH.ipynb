{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorchLab04.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU6UZ7Q_pAoN"
      },
      "source": [
        "#### 여러개의 정보로부터 하나의 예"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kJOBX4OpHD6"
      },
      "source": [
        "simple linear regression\n",
        "- 1개의 정보로 1개의 예측\n",
        "\n",
        "multivariate linear regression\n",
        "- 여러개의 정보로 1개의 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEVpdfXXpDUq"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5-MyTQrpTGh"
      },
      "source": [
        "x_train = torch.FloatTensor([[73,80,75],\n",
        "                             [93,88,93],\n",
        "                             [89,91,90],\n",
        "                             [73,66,70]])\n",
        "y_train = torch.FloatTensor([[152],[185],[196],[142]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcnpilM0pp5W"
      },
      "source": [
        "# H(x) 계산\n",
        "#hypothesis = x_train.matmul(W) + b\n",
        "\n",
        "#cost function : MSE\n",
        "#cost = torch.mean((hypothesis - y_train)**2)\n",
        "\n",
        "#Gradient Descent\n",
        "#위와 같음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA4iXRiSp2ty",
        "outputId": "e4ed2a52-379d-44c1-eba8-1302b5ba978b"
      },
      "source": [
        "#데이터\n",
        "\n",
        "x_train = torch.FloatTensor([[73,80,75],\n",
        "                             [93,88,93],\n",
        "                             [89,91,90],\n",
        "                             [73,66,70]])\n",
        "y_train = torch.FloatTensor([[152],[185],[196],[142]])\n",
        "\n",
        "#모델 초기화\n",
        "\n",
        "W = torch.zeros((3,1), requires_grad= True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "#optimizer 설정\n",
        "optimizer = optim.SGD([W,b], lr=1e-5)\n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs+1):\n",
        "  #H(x)계산\n",
        "  hypothesis = x_train.matmul(W) +b\n",
        "\n",
        "  #cost gradient 계산\n",
        "  cost = torch.mean((hypothesis - y_train)**2)\n",
        "  # gradient = 2*torch.mean((W*x_train -y_train)* x_train)\n",
        "\n",
        "  print(\"Epoch {:4d}/{} , Cost : {:.6f}\". format(epoch,\n",
        "                              nb_epochs,  cost.item()))\n",
        "\n",
        "  #cost.item() : cost의 값\n",
        "\n",
        "  #cost gradient로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20 , Cost : 28977.250000\n",
            "Epoch    1/20 , Cost : 10244.185547\n",
            "Epoch    2/20 , Cost : 3636.618164\n",
            "Epoch    3/20 , Cost : 1305.981689\n",
            "Epoch    4/20 , Cost : 483.914276\n",
            "Epoch    5/20 , Cost : 193.952896\n",
            "Epoch    6/20 , Cost : 91.676903\n",
            "Epoch    7/20 , Cost : 55.601357\n",
            "Epoch    8/20 , Cost : 42.876610\n",
            "Epoch    9/20 , Cost : 38.387985\n",
            "Epoch   10/20 , Cost : 36.804485\n",
            "Epoch   11/20 , Cost : 36.245632\n",
            "Epoch   12/20 , Cost : 36.048275\n",
            "Epoch   13/20 , Cost : 35.978397\n",
            "Epoch   14/20 , Cost : 35.953461\n",
            "Epoch   15/20 , Cost : 35.944447\n",
            "Epoch   16/20 , Cost : 35.940933\n",
            "Epoch   17/20 , Cost : 35.939415\n",
            "Epoch   18/20 , Cost : 35.938652\n",
            "Epoch   19/20 , Cost : 35.938179\n",
            "Epoch   20/20 , Cost : 35.937641\n",
            "Epoch    0/20 , Cost : 28977.250000\n",
            "Epoch    1/20 , Cost : 10244.185547\n",
            "Epoch    2/20 , Cost : 3636.618164\n",
            "Epoch    3/20 , Cost : 1305.981689\n",
            "Epoch    4/20 , Cost : 483.914276\n",
            "Epoch    5/20 , Cost : 193.952896\n",
            "Epoch    6/20 , Cost : 91.676903\n",
            "Epoch    7/20 , Cost : 55.601357\n",
            "Epoch    8/20 , Cost : 42.876610\n",
            "Epoch    9/20 , Cost : 38.387985\n",
            "Epoch   10/20 , Cost : 36.804485\n",
            "Epoch   11/20 , Cost : 36.245632\n",
            "Epoch   12/20 , Cost : 36.048275\n",
            "Epoch   13/20 , Cost : 35.978397\n",
            "Epoch   14/20 , Cost : 35.953461\n",
            "Epoch   15/20 , Cost : 35.944447\n",
            "Epoch   16/20 , Cost : 35.940933\n",
            "Epoch   17/20 , Cost : 35.939415\n",
            "Epoch   18/20 , Cost : 35.938652\n",
            "Epoch   19/20 , Cost : 35.938179\n",
            "Epoch   20/20 , Cost : 35.937641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKrQLGRzqhSb"
      },
      "source": [
        "#### nn.Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAovThyGs-C4"
      },
      "source": [
        "nn.Module 을 상속해서 모델 생성\n",
        "nn.Linear(3,1)\n",
        "- 입력 차원 : 3\n",
        "- 출력 차원 : 1\n",
        "\n",
        "Hypothesis 계산은 forward() 에서\n",
        "Gradient 계산은 pytorch가 알아서 해줌 : backward()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imYj4uwVqSSA"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultivariateLinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(3,1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n",
        "\n",
        "# hypothesis = model(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou5n713rtRWf"
      },
      "source": [
        "#### Cost fuction\n",
        "\n",
        "F.mse_loss\n",
        "\n",
        "torch.nn.functional 에서 제공하는 loss function 사용\n",
        "\n",
        "쉽게 다른 loss와 교체 가능 (l1_loss, smooth_l1_loss 등,,)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZapAJZIsLJj"
      },
      "source": [
        "#cost = F.mse_loss(prediction, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PlQ0FkttpDm",
        "outputId": "caf3f12b-2c38-4522-989d-5b1e492e9fa0"
      },
      "source": [
        "# 데이터\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "\n",
        "# 모델 초기화\n",
        "model = MultivariateLinearRegressionModel()\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs+1):\n",
        "    \n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "    \n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "    \n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # 20번마다 로그 출력\n",
        "    print('Epoch {:4d}/{} Hypothesis : {} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs,  prediction.squeeze().detach(), cost.item()\n",
        "    ))\n",
        "\n",
        "    #prediction.squeeze().detach() :  예측한 값"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20 Hypothesis : tensor([ 92.3243, 112.2484, 109.9234, 120.2216,  85.4508]) Cost: 4540.979492\n",
            "Epoch    1/20 Hypothesis : tensor([118.6373, 143.8752, 141.0855, 154.1564, 109.5742]) Cost: 1424.195312\n",
            "Epoch    2/20 Hypothesis : tensor([133.3688, 161.5819, 158.5320, 173.1552, 123.0802]) Cost: 447.249207\n",
            "Epoch    3/20 Hypothesis : tensor([141.6163, 171.4954, 168.2997, 183.7919, 130.6418]) Cost: 141.027802\n",
            "Epoch    4/20 Hypothesis : tensor([146.2336, 177.0457, 173.7681, 189.7469, 134.8754]) Cost: 45.043861\n",
            "Epoch    5/20 Hypothesis : tensor([148.8186, 180.1532, 176.8297, 193.0809, 137.2458]) Cost: 14.957491\n",
            "Epoch    6/20 Hypothesis : tensor([150.2657, 181.8930, 178.5437, 194.9474, 138.5730]) Cost: 5.526789\n",
            "Epoch    7/20 Hypothesis : tensor([151.0757, 182.8672, 179.5033, 195.9924, 139.3162]) Cost: 2.570533\n",
            "Epoch    8/20 Hypothesis : tensor([151.5291, 183.4127, 180.0405, 196.5774, 139.7324]) Cost: 1.643648\n",
            "Epoch    9/20 Hypothesis : tensor([151.7828, 183.7182, 180.3412, 196.9048, 139.9656]) Cost: 1.352848\n",
            "Epoch   10/20 Hypothesis : tensor([151.9247, 183.8893, 180.5095, 197.0882, 140.0962]) Cost: 1.261454\n",
            "Epoch   11/20 Hypothesis : tensor([152.0040, 183.9852, 180.6037, 197.1907, 140.1695]) Cost: 1.232561\n",
            "Epoch   12/20 Hypothesis : tensor([152.0483, 184.0390, 180.6564, 197.2481, 140.2107]) Cost: 1.223239\n",
            "Epoch   13/20 Hypothesis : tensor([152.0730, 184.0692, 180.6859, 197.2802, 140.2339]) Cost: 1.220070\n",
            "Epoch   14/20 Hypothesis : tensor([152.0866, 184.0862, 180.7024, 197.2982, 140.2470]) Cost: 1.218835\n",
            "Epoch   15/20 Hypothesis : tensor([152.0941, 184.0958, 180.7115, 197.3081, 140.2544]) Cost: 1.218191\n",
            "Epoch   16/20 Hypothesis : tensor([152.0982, 184.1013, 180.7166, 197.3137, 140.2587]) Cost: 1.217730\n",
            "Epoch   17/20 Hypothesis : tensor([152.1004, 184.1044, 180.7194, 197.3167, 140.2613]) Cost: 1.217332\n",
            "Epoch   18/20 Hypothesis : tensor([152.1015, 184.1063, 180.7210, 197.3184, 140.2629]) Cost: 1.216947\n",
            "Epoch   19/20 Hypothesis : tensor([152.1019, 184.1074, 180.7218, 197.3193, 140.2639]) Cost: 1.216578\n",
            "Epoch   20/20 Hypothesis : tensor([152.1021, 184.1082, 180.7222, 197.3198, 140.2645]) Cost: 1.216210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tZJFEmByp9v"
      },
      "source": [
        "엄청난 양의 데이터를 한번에 학습할수 없음\n",
        "- 너무 느리다\n",
        "- 하드웨어 적으로 불가능\n",
        "\n",
        "그래서 일부분의 데이터로만 학습한다!\n",
        "\n",
        "-> mini-batch\n",
        "\n",
        "업데이트를 좀 더 빠르게 가능(장점)\n",
        "전체 데이터를 쓰지 않아 잘못된 방향으로 업데이트 될 수도 있음 (단점)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOQFPyEgzFNZ"
      },
      "source": [
        "#### PyTorch Dataset\n",
        "\n",
        "torch.utils.data.Dataset 상속\n",
        "\n",
        "__ len __()\n",
        "- 이 데이터의 총 데이터 수\n",
        "\n",
        "__ getitem __()\n",
        "- 어떠한 인덱스 idx를 받았을 때, 그에 상응하는 입출력 데이터를 반환\n",
        "\n",
        "torch.utils.data.Dataloader 사용\n",
        "\n",
        "batch_size \n",
        "- 각 minibatch의 크기\n",
        "- 통상적으로 2의 제곱\n",
        "\n",
        "shuffle = True\n",
        "- 데이터 섞기\n",
        "\n",
        "enumerate(dataloader)\n",
        "- minibatch 인덱스와 데이터를 받는다\n",
        "\n",
        "len(dataloader)\n",
        "- 한 epoch당 minibatch 개수"
      ]
    }
  ]
}