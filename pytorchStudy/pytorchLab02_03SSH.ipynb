{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorchLab02-03.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU2xo_1Jd02q"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwyz0fPoguZ0"
      },
      "source": [
        "#### 1. 데이터 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11nSmJPJeC9S"
      },
      "source": [
        "x_train = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[2],[4],[6]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2XNnnU_gzX3"
      },
      "source": [
        "#### 2. hypothesis 초기화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kRw5lq_fKVx"
      },
      "source": [
        "Weight 와 Bias 0으로 초기화하기 (항상 출력 0을 예측) 처음에 어떤 입력을 받아도 0을 받음\n",
        "\n",
        "requires_grad = True\n",
        "W와 b를 학습하라고 정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jllaLxgKelVI"
      },
      "source": [
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "hypothesis = x_train*W +b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27R3vOjig7JF"
      },
      "source": [
        "#### 3. Optimizer 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AZsvONufH9p"
      },
      "source": [
        "optimizer = optim.SGD([W,b], lr = 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egz2zNtyfkWi"
      },
      "source": [
        "torch.optim 라이브러리 사용\n",
        "- [W,b] 는 학습할 tensor들\n",
        "- lr =0.01 은 learning rate\n",
        "\n",
        "항상 붙어다니는 3줄\n",
        "- zero_grad() 로 gradient 초기화\n",
        "- backward() 로 gradient 계산\n",
        "- step()으로 개선"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2E3pfdcg_4v"
      },
      "source": [
        "#### 반복 \n",
        "\n",
        "1. Hypothesis 예측\n",
        "2. Cost 계산\n",
        "3. Optimizer 로 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VopblYL4favQ"
      },
      "source": [
        "nb_epochs = 20\n",
        "\n",
        "for epoch in range(1, nb_epochs+1):\n",
        "  hypothesis = x_train*W + b\n",
        "  cost = torch.mean((hypothesis - y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVEfPkmnlkbT"
      },
      "source": [
        "### Simpler Hypothesis Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iywxIujJf0ab"
      },
      "source": [
        "x_train = torch.FloatTensor([[1],[2],[3]])\n",
        "y_train = torch.FloatTensor([[1],[2],[3]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHj9V5wilmcZ"
      },
      "source": [
        "#모델 초기화\n",
        "\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "# b = torch.zeros(1, requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "208A_IodltjO"
      },
      "source": [
        "# H(x) = x가 가장 정확한 모델 \n",
        "# W =1 이 가장 좋은 숫자\n",
        "\n",
        "# 모델의 좋고 나쁨을 어떻게 알까?\n",
        "# Cost function ! (적을 수록 좋은 model)\n",
        "# cost = torch.mean((hypothesis - y_train)**2)\n",
        "\n",
        "# Cost function 을 최소화 : Gradient Descent\n",
        "# W := W - a ▽W"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eseAvkAalyXV",
        "outputId": "bbdea6fa-448d-48a6-ea1c-6d103204089c"
      },
      "source": [
        "nb_epochs = 20\n",
        "lr = 0.1\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "  #H(x)계산\n",
        "  hypothesis = x_train*W\n",
        "\n",
        "  #cost gradient 계산\n",
        "  cost = torch.mean((hypothesis - y_train)**2)\n",
        "  gradient = 2*torch.mean((W*x_train -y_train)* x_train)\n",
        "\n",
        "  print(\"Epoch {:4d}/{} W: {:.3f}, Cost : {:.6f}\". format(epoch,\n",
        "                              nb_epochs, W.item(), cost.item()))\n",
        "  #W.item(): W의 값\n",
        "  #cost.item() : cost의 값\n",
        "\n",
        "  #cost gradient로 H(x) 개선\n",
        "  W -= lr * gradient"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20 W: 1.000, Cost : 0.000000\n",
            "Epoch    1/20 W: 1.000, Cost : 0.000000\n",
            "Epoch    2/20 W: 1.000, Cost : 0.000000\n",
            "Epoch    3/20 W: 1.000, Cost : 0.000000\n",
            "Epoch    4/20 W: 1.000, Cost : 0.000000\n",
            "Epoch    5/20 W: 1.000, Cost : 0.000000\n",
            "Epoch    6/20 W: 1.000, Cost : 0.000000\n",
            "Epoch    7/20 W: 1.000, Cost : 0.000000\n",
            "Epoch    8/20 W: 1.000, Cost : 0.000000\n",
            "Epoch    9/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   10/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   11/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   12/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   13/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   14/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   15/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   16/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   17/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   18/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   19/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   20/20 W: 1.000, Cost : 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAuq-hG3njYt"
      },
      "source": [
        "#### Gradient Descent with torch.otim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgrfgBZdnnGg"
      },
      "source": [
        "torch.optim 으로도 gradient descent 를 할 수 있다\n",
        "\n",
        "- 시작할때 Optimizer 정의\n",
        "- optimizer.zero_grad() 로 gradient를 0으로 초기화\n",
        "- cost.backward() 로 gradient 계산\n",
        "- optimizer.step() 으로 gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-JVqdHVoA1A"
      },
      "source": [
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W], lr=0.15)\n",
        "\n",
        "# cost 로 H(x) 개선\n",
        "\n",
        "optimizer.zero_grad()\n",
        "cost.backward()\n",
        "optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saj0itU7oBRG",
        "outputId": "2105417d-4944-4a3f-b073-d7caa3de36b1"
      },
      "source": [
        "nb_epochs = 20\n",
        "optimizer = optim.SGD([W], lr=0.15)\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "  #H(x)계산\n",
        "  hypothesis = x_train*W\n",
        "\n",
        "  #cost gradient 계산\n",
        "  cost = torch.mean((hypothesis - y_train)**2)\n",
        "  # gradient = 2*torch.mean((W*x_train -y_train)* x_train)\n",
        "\n",
        "  print(\"Epoch {:4d}/{} W: {:.3f}, Cost : {:.6f}\". format(epoch,\n",
        "                              nb_epochs, W.item(), cost.item()))\n",
        "  #W.item(): W의 값\n",
        "  #cost.item() : cost의 값\n",
        "\n",
        "  #cost gradient로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20 W: 0.000, Cost : 4.666667\n",
            "Epoch    1/20 W: 1.400, Cost : 0.746667\n",
            "Epoch    2/20 W: 0.840, Cost : 0.119467\n",
            "Epoch    3/20 W: 1.064, Cost : 0.019115\n",
            "Epoch    4/20 W: 0.974, Cost : 0.003058\n",
            "Epoch    5/20 W: 1.010, Cost : 0.000489\n",
            "Epoch    6/20 W: 0.996, Cost : 0.000078\n",
            "Epoch    7/20 W: 1.002, Cost : 0.000013\n",
            "Epoch    8/20 W: 0.999, Cost : 0.000002\n",
            "Epoch    9/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   10/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   11/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   12/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   13/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   14/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   15/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   16/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   17/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   18/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   19/20 W: 1.000, Cost : 0.000000\n",
            "Epoch   20/20 W: 1.000, Cost : 0.000000\n"
          ]
        }
      ]
    }
  ]
}